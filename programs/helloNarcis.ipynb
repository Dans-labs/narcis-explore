{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Hello-NARCIS\" data-toc-modified-id=\"Hello-NARCIS-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Hello NARCIS</a></span></li><li><span><a href=\"#Preparation\" data-toc-modified-id=\"Preparation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Config\" data-toc-modified-id=\"Config-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Config</a></span></li><li><span><a href=\"#Start-Docker\" data-toc-modified-id=\"Start-Docker-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Start Docker</a></span></li><li><span><a href=\"#Connect-to-MongoDB\" data-toc-modified-id=\"Connect-to-MongoDB-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Connect to MongoDB</a></span></li></ul></li><li><span><a href=\"#Key-value-generation\" data-toc-modified-id=\"Key-value-generation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Key value generation</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Load data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Top-level-fields\" data-toc-modified-id=\"Top-level-fields-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Top level fields</a></span></li></ul></li><li><span><a href=\"#Inventory-of-keys\" data-toc-modified-id=\"Inventory-of-keys-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Inventory of keys</a></span><ul class=\"toc-item\"><li><span><a href=\"#Nested-keys\" data-toc-modified-id=\"Nested-keys-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Nested keys</a></span></li></ul></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Results</a></span></li><li><span><a href=\"#Appendix\" data-toc-modified-id=\"Appendix-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Appendix</a></span><ul class=\"toc-item\"><li><span><a href=\"#Use-variety\" data-toc-modified-id=\"Use-variety-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Use <em>variety</em></a></span></li><li><span><a href=\"#Preparation\" data-toc-modified-id=\"Preparation-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Preparation</a></span></li><li><span><a href=\"#Run-variety\" data-toc-modified-id=\"Run-variety-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Run <em>variety</em></a></span></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Results</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello NARCIS\n",
    "\n",
    "We explore a dump of the [NARCIS](https://www.narcis.nl) data.\n",
    "The dump has been taken bij \n",
    "[Emil Bode](https://dans.knaw.nl/nl/over/organisatie-beleid/medewerkers/bode)\n",
    "in December 2017.\n",
    "He has prepared it as MongoDB database contents in a Docker container.\n",
    "This container is obtainable from DataVerse:\n",
    "[NARCIS metadata in nldidlnorm format](http://hdl.handle.net/10411/FTZVH4).\n",
    "Next to the dump is a *readme* that tells you exactly how to query the data locally.\n",
    "\n",
    "The purpose of this notebook is an initial scan of the full database contents.\n",
    "The database is called `NARCIS`, and in it is just one collection, `Dec2017`, with over 1,5 million\n",
    "documents.\n",
    "\n",
    "A document is a dictionary of keys and values, where values may be numbers, strings, dates, but also lists\n",
    "of values and also dictionaries of keys and values.\n",
    "The nesting of lists and dictionaries can be arbitrarily deep.\n",
    "\n",
    "Documents do not have to conform to any schema. Most likely, there are a few dominant schemata,\n",
    "but also likely: there might be outliers.\n",
    "\n",
    "We assume no previous knowledge of NARCIS, so we want to explore the data from scratch.\n",
    "\n",
    "This notebook performs a first step:\n",
    "* we convert the documents into sets of key values, and write them economically to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "We assume that you have a directory `local` under your home directory, with a directory `narcis` in it.\n",
    "We assume that you have downloaded the dump from DataVerse and placed it under this `narcis` directory.\n",
    "\n",
    "If you have it in a different location on your system, you can adapt the notebook to your own situation\n",
    "by editing some values in the config section below.\n",
    "\n",
    "You need to have [Docker](https://www.docker.com/get-docker) installed on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T10:12:33.014500Z",
     "start_time": "2018-02-08T10:12:32.919054Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "from utils import readData, writeData, getTopKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config\n",
    "\n",
    "Specify the location of the database dump here; also the local location of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T10:12:34.561074Z",
     "start_time": "2018-02-08T10:12:34.525208Z"
    }
   },
   "outputs": [],
   "source": [
    "DUMP_DIR = os.path.expanduser('~/local/narcis/MongoDB-NARCIS-Dec17')\n",
    "\n",
    "REPO_DIR = os.path.expanduser('~/github/Dans-labs/narcis-explore')\n",
    "\n",
    "TEMP_NAME = '_temp'\n",
    "TEMP_DIR = f'{REPO_DIR}/{TEMP_NAME}'\n",
    "\n",
    "RESULT_NAME = 'results'\n",
    "RESULT_DIR = f'{REPO_DIR}/{RESULT_NAME}'\n",
    "\n",
    "FIELDS_VAR_NAME = 'fields-variety.txt'\n",
    "FIELDS_VAR_FILE = f'{RESULT_DIR}/{FIELDS_VAR_NAME}'\n",
    "\n",
    "FIELDS_NAME = 'fields.tfx'\n",
    "FIELDS_FILE = f'{TEMP_DIR}/{FIELDS_NAME}'\n",
    "DOC_NAME = 'docId.tfx'\n",
    "DOC_FILE = f'{TEMP_DIR}/{DOC_NAME}'\n",
    "KEY_NAME = 'keys.tfx'\n",
    "KEY_FILE = f'{TEMP_DIR}/{KEY_NAME}'\n",
    "VAL_NAME = 'values.tfx'\n",
    "VAL_FILE = f'{TEMP_DIR}/{VAL_NAME}'\n",
    "\n",
    "FIELD_FREQ_NAME = 'fieldFreqs.tsv'\n",
    "FIELD_FREQ_FILE = f'{TEMP_DIR}/{FIELD_FREQ_NAME}'\n",
    "\n",
    "for outDir in (TEMP_DIR, RESULT_DIR):\n",
    "    os.makedirs(outDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "RESULT_NAME": "results",
     "TEMP_NAME": "_temp"
    }
   },
   "source": [
    "If we generate large files, we do so in a temporary directory `{{TEMP_NAME}}`, in the repository itself.\n",
    "The repository lists `{{TEMP_NAME}}` in its `.gitignore` file, so output will not be sent to GitHub.\n",
    "\n",
    "Result files will be generated in `{{RESULT_NAME}}`, also inside the repo. These files will be sent to GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Docker\n",
    "\n",
    "Below are the magic commands to start and stop the relevant Docker container.\n",
    "They are shell commands, not Python commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to stop Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T10:12:39.722281Z",
     "start_time": "2018-02-08T10:12:38.190590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NARCIS\n",
      "NARCIS\n"
     ]
    }
   ],
   "source": [
    "!docker stop NARCIS\n",
    "!docker rm NARCIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell a Docker container is started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T10:12:42.916172Z",
     "start_time": "2018-02-08T10:12:42.176141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e6307c30296a19f7905dccb0ae0425d48588ac4ce08376f5516b9d491bac21e8\r\n"
     ]
    }
   ],
   "source": [
    "!docker run --name NARCIS -v {DUMP_DIR}:/data/db -p 27019:27017 -d mongo --logpath /data/db/log.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to MongoDB\n",
    "Now there is a MongoDb behind port 27019 that we can connect to.\n",
    "\n",
    "We make the connection and get some very basic statistics about the contents of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T10:12:46.685421Z",
     "start_time": "2018-02-08T10:12:45.647908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NARCIS', 'admin', 'config', 'local']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient('mongodb://localhost:27019/')\n",
    "client.database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to the Dec2017 collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T10:12:49.544297Z",
     "start_time": "2018-02-08T10:12:49.530297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dec2017']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1622397"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DBN = client.NARCIS\n",
    "print(DBN.collection_names())\n",
    "DBND = DBN.Dec2017\n",
    "DBND.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key value generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to treat a document as a generator of key-value pairs, \n",
    "where keys are hierarchical keys and values are scalar values.\n",
    "We convert scalar values to strings, and escape newlines.\n",
    "\n",
    "We then write the key value pairs to file.\n",
    "If we just write them naively as tuples `(_id, hkey, value)` where\n",
    "`hkey` is the hierarchical key within the document, \n",
    "we end up with a file of 5GB.\n",
    "\n",
    "In order to save space we leave out the `_id`, but instead we insert a blank line between docs.\n",
    "\n",
    "We make a mapping between the doc-ids and positive numbers.\n",
    "\n",
    "Furthermore, instead of specifying keys, we map them to positive numbers.\n",
    "\n",
    "Same with keys.\n",
    "\n",
    "We save the mappings from numbers to document ids, keys and values as single column files.\n",
    "The value on line *n* is the value to which number *n* is mapped to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T10:12:55.092739Z",
     "start_time": "2018-02-08T10:12:55.078948Z"
    }
   },
   "outputs": [],
   "source": [
    "def kvPairs(key, val):\n",
    "    if type(val) is list:\n",
    "        for (i, v) in enumerate(val):\n",
    "            for y in kvPairs(key + (str(i+1),), v):\n",
    "                yield y\n",
    "    elif type(val) is dict:\n",
    "        for (k, v) in val.items():\n",
    "            for y in kvPairs(key + (k,), v):\n",
    "                yield y\n",
    "    else:\n",
    "        yield (key, str(val).replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude some information from the data: some top-level keys and their values can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T10:12:56.539528Z",
     "start_time": "2018-02-08T10:12:56.535830Z"
    }
   },
   "outputs": [],
   "source": [
    "excludeKeys = set('''\n",
    "    setSpec\n",
    "'''.strip().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply the filtering.\n",
    "We also treat the `_id` field in a special way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T10:13:41.816612Z",
     "start_time": "2018-02-08T10:13:41.803951Z"
    }
   },
   "outputs": [],
   "source": [
    "def docPairs(pairs):\n",
    "    docId = None\n",
    "    filteredPairs = []\n",
    "    for (key, value) in pairs:\n",
    "        if key[0] in excludeKeys:\n",
    "            pass\n",
    "        elif key == ('_id',):\n",
    "            docId = value\n",
    "        else:\n",
    "            hKey = '.'.join(key)\n",
    "            filteredPairs.append((hKey, value))\n",
    "    return (docId, filteredPairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the big loop where all documents are converted into key value pairs which get written to file.\n",
    "\n",
    "It takes half an hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T11:06:55.200821Z",
     "start_time": "2018-02-08T10:13:58.537368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 100000 docs =>   9366214 pairs\n",
      "\t 200000 docs =>  18518217 pairs\n",
      "\t 300000 docs =>  27784517 pairs\n",
      "\t 400000 docs =>  39483221 pairs\n",
      "\t 500000 docs =>  49967908 pairs\n",
      "\t 600000 docs =>  61319571 pairs\n",
      "\t 700000 docs =>  71707654 pairs\n",
      "\t 800000 docs =>  83571814 pairs\n",
      "\t 900000 docs =>  95045898 pairs\n",
      "\t1000000 docs => 109394801 pairs\n",
      "\t1100000 docs => 120065283 pairs\n",
      "\t1200000 docs => 129697097 pairs\n",
      "\t1300000 docs => 141362774 pairs\n",
      "\t1400000 docs => 152096820 pairs\n",
      "\t1500000 docs => 164118222 pairs\n",
      "\t1600000 docs => 177606033 pairs\n",
      "\t1622397 docs => 180762634 pairs\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "chunk = 100000\n",
    "limit = -1\n",
    "nkv = 0\n",
    "\n",
    "keys = []\n",
    "keysIndex = {}\n",
    "values = []\n",
    "valuesIndex = {}\n",
    "docIds = []\n",
    "fields = []\n",
    "\n",
    "for (docNumber, doc) in enumerate(DBND.find()):\n",
    "    j += 1\n",
    "    i += 1\n",
    "    (docId, pairs) = docPairs(kvPairs((), doc))\n",
    "    docIds.append(docId)\n",
    "    theFields = {}\n",
    "    for (key, value) in pairs:\n",
    "        keyNumber = keysIndex.get(key, None)\n",
    "        if keyNumber is None:\n",
    "            keyNumber = len(keys)\n",
    "            keysIndex[key] = keyNumber\n",
    "            keys.append(key)\n",
    "        valNumber = valuesIndex.get(value, None)\n",
    "        if valNumber is None:\n",
    "            valNumber = len(values)\n",
    "            valuesIndex[value] = valNumber\n",
    "            values.append(value)\n",
    "        theFields[keyNumber] = valNumber\n",
    "        nkv += 1\n",
    "    fields.append(theFields)\n",
    "    if j == chunk:\n",
    "        j = 0\n",
    "        print(f'\\t{i:>7} docs => {nkv:>9} pairs')\n",
    "    if limit > 0 and i >= limit:\n",
    "        break\n",
    "print(f'\\t{i:>7} docs => {nkv:9} pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write data to disk in a way that facilitates quick reuse: pickled and gzipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:42:51.663003Z",
     "start_time": "2018-02-08T14:42:51.618722Z"
    }
   },
   "outputs": [],
   "source": [
    "writeData(KEY_FILE, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:43:46.704861Z",
     "start_time": "2018-02-08T14:42:52.886268Z"
    }
   },
   "outputs": [],
   "source": [
    "writeData(VAL_FILE, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:44:19.841072Z",
     "start_time": "2018-02-08T14:44:18.719500Z"
    }
   },
   "outputs": [],
   "source": [
    "writeData(DOC_FILE, docIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:45:37.431982Z",
     "start_time": "2018-02-08T14:44:33.142576Z"
    }
   },
   "outputs": [],
   "source": [
    "writeData(FIELDS_FILE, fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Further processing can now start by reading the files just generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top level fields\n",
    "We count how often each top-level field occurs.\n",
    "We make separate counts for empty and non-empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:46:04.767478Z",
     "start_time": "2018-02-08T14:46:04.731832Z"
    }
   },
   "outputs": [],
   "source": [
    "keys = readData(KEY_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:46:44.694937Z",
     "start_time": "2018-02-08T14:46:10.638861Z"
    }
   },
   "outputs": [],
   "source": [
    "values = readData(VAL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:46:52.219297Z",
     "start_time": "2018-02-08T14:46:51.564070Z"
    }
   },
   "outputs": [],
   "source": [
    "docIds = readData(DOC_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:48:22.695688Z",
     "start_time": "2018-02-08T14:46:55.793215Z"
    }
   },
   "outputs": [],
   "source": [
    "fields = readData(FIELDS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:48:32.449466Z",
     "start_time": "2018-02-08T14:48:32.394421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DAI',\n",
       " 'GlobalIDs',\n",
       " 'ID',\n",
       " 'Journal',\n",
       " 'Keywords',\n",
       " 'NumberofIDs',\n",
       " 'access',\n",
       " 'date_harv',\n",
       " 'date_header',\n",
       " 'date_orig',\n",
       " 'filenr',\n",
       " 'nldidlnorm',\n",
       " 'originURL']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topKeys = getTopKeys(keys)\n",
    "sorted(set(topKeys.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inventory of keys\n",
    "\n",
    "The next step is to have a closer look at the top-level keys of all the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:49:50.658059Z",
     "start_time": "2018-02-08T14:48:40.031878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 top keys\n"
     ]
    }
   ],
   "source": [
    "allTopKeys = collections.Counter()\n",
    "\n",
    "for pairs in fields:\n",
    "    myTopKeys = set(topKeys[key] for key in pairs)\n",
    "    for mtk in myTopKeys: allTopKeys[mtk] += 1\n",
    "print(f'There are {len(allTopKeys)} top keys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the keys and how often they occur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:49:55.079288Z",
     "start_time": "2018-02-08T14:49:55.038384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobalIDs            1622397x\n",
      "ID                   1622397x\n",
      "NumberofIDs          1622397x\n",
      "access               1622397x\n",
      "date_harv            1622397x\n",
      "date_header          1622397x\n",
      "date_orig            1622397x\n",
      "filenr               1622397x\n",
      "nldidlnorm           1622397x\n",
      "originURL            1622397x\n",
      "Journal              1124764x\n",
      "DAI                  1003441x\n",
      "Keywords              746235x\n"
     ]
    }
   ],
   "source": [
    "for (key, amount) in sorted(allTopKeys.items(), key=lambda x: (-x[1], x[0])):\n",
    "    print(f'{key:<20} {amount:>7}x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every document in NARCIS has mostly the same set of top level keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested keys\n",
    "\n",
    "We want to explore a distribution of all keys, also the ones that occur\n",
    "(deeply) nested in documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:51:56.226832Z",
     "start_time": "2018-02-08T14:50:07.956685Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1569 distinct keys encountered\n"
     ]
    }
   ],
   "source": [
    "nestedKeys = collections.Counter()\n",
    "\n",
    "for pairs in fields:\n",
    "    for key in pairs:\n",
    "        nestedKeys[key] += 1\n",
    "print(f'{len(nestedKeys)} distinct keys encountered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "FIELD_FREQ_NAME": "fieldFreqs.tsv"
    }
   },
   "source": [
    "We list the keys in order of frequency, most frequent ones first.\n",
    "The result is writen to `{{FIELD_FREQ_NAME}}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:52:04.465248Z",
     "start_time": "2018-02-08T14:52:04.376142Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(FIELD_FREQ_FILE, 'w') as fh:\n",
    "    for (k, n) in sorted(nestedKeys.items(), key=lambda x: (-x[1], x[0])):\n",
    "        fh.write(f'{n:>7}\\t{keys[k]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See them on GitHub: [nested keys overview](https://github.com/Dans-labs/narcis-explore/blob/master/results/fieldFreqs.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:52:06.509180Z",
     "start_time": "2018-02-08T14:52:06.102922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1622397\tID.1\r\n",
      "1622397\tfilenr.1\r\n",
      "1622397\tdate_header.1\r\n",
      "1622397\tdate_harv.1\r\n",
      "1622397\tdate_orig.1\r\n",
      "1622397\tGlobalIDs.1.1\r\n",
      "1622397\tNumberofIDs.1\r\n",
      "1622397\toriginURL.1\r\n",
      "1622397\taccess.1\r\n",
      "1622397\tnldidlnorm.1.Descriptor.Statement.Identifier.1\r\n",
      "1622397\tnldidlnorm.1.Descriptor.Statement._attrs.1\r\n",
      "1622397\tnldidlnorm.1.Descriptor1.Statement.modified.1\r\n",
      "1622397\tnldidlnorm.1.Descriptor1.Statement._attrs.1\r\n",
      "1622397\tnldidlnorm.1.Component.Resource.1\r\n",
      "1622397\tnldidlnorm.1.Component.Resource.2\r\n",
      "1622397\tnldidlnorm.1.Item.Descriptor.Statement.type.1\r\n",
      "1622397\tnldidlnorm.1.Item.Descriptor.Statement._attrs.1\r\n",
      "1622397\tnldidlnorm.1.Item.Component.Resource.mods.name.role.roleTerm.text.1\r\n",
      "1622397\tnldidlnorm.1.Item.Component.Resource.mods.name.role.roleTerm._attrs.1\r\n",
      "1622397\tnldidlnorm.1.Item.Component.Resource.mods.titleInfo.title.1\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 {FIELD_FREQ_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T14:52:07.723196Z",
     "start_time": "2018-02-08T14:52:07.440667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.relatedItem.name7.namePart.text.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.relatedItem.name7.namePart._attrs.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.relatedItem.name7.namePart1.text.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.relatedItem.name7.namePart1._attrs.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.relatedItem.name7._attrs.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.relatedItem.name8.namePart.text.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.relatedItem.name8.namePart._attrs.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.relatedItem.name8.namePart1.text.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.relatedItem.name8.namePart1._attrs.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.relatedItem.name8._attrs.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.name6.affiliation9.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.name6.affiliation0.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.name4.nameIdentifier2.text.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.name4.nameIdentifier2._attrs.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.name4.nameIdentifier2._attrs.2\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.originInfo.place1.placeTerm.text.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.originInfo.place1.placeTerm._attrs.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.name5.role.roleTerm2.text.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.name5.role.roleTerm2._attrs.1\r\n",
      "      1\tnldidlnorm.1.Item.Component.Resource.mods.name5.role.roleTerm2._attrs.2\r\n"
     ]
    }
   ],
   "source": [
    "!tail -20 {FIELD_FREQ_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "DOC_NAME": "docId.tfx",
     "FIELDS_NAME": "fields.tfx",
     "KEY_NAME": "keys.tfx",
     "VAL_NAME": "values.tfx"
    }
   },
   "source": [
    "## Results\n",
    "The product of this notebook are the files\n",
    "\n",
    "* `{{FIELDS_NAME}}` all key value pairs of all documents,\n",
    "  where keys and values are replaced by their numerical index\n",
    "* `{{DOC_NAME}}` single column file containing all document ids in order of their index number\n",
    "* `{{KEY_NAME}}` single column file containing all keys in order of their index number\n",
    "* `{{VAL_NAME}}` single column file containing all values in order of their index number\n",
    "\n",
    "In other notebooks we will use this file, and conduct further explorations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "The rest of this notebook is an alternative approach that we will not build on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use *variety*\n",
    "\n",
    "Normally, you can speed up data processing by having the database use its query engine to its full potential.\n",
    "Using `mapReduce` inside MongoDb as indicated on\n",
    "[stack overflow](https://stackoverflow.com/questions/2298870/mongodb-get-names-of-all-keys-in-collection)\n",
    "could do the trick. But the accepted answer there does not do  nested keys.\n",
    "So we have to write a MongoDb function for mapReduce, which means writing something in Javascript.\n",
    "\n",
    "It turns out that somebody has already done this, and made a nice library out of it:\n",
    "[variety](https://github.com/variety/variety). \n",
    "This is a tool to explore the dominant scheme of a MongoDB and its outlier documents.\n",
    "\n",
    "However, the performance is much worse than the previous method:\n",
    "going this way takes you a whopping 80 minutes.\n",
    "We only show how to do it, generate the results, but we do not recommend it.\n",
    "\n",
    "If you want to try it yourself, there is extra preparation to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "\n",
    "You must have *MongoDb* and *Node* installed.\n",
    "\n",
    "Install *variety*:\n",
    "\n",
    "```\n",
    "npm install variety-cli -g\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run *variety*\n",
    "This is a javascript program; we need Node to run it.\n",
    "The next cell takes well over an hour!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T18:57:10.192856Z",
     "start_time": "2018-02-06T17:38:32.731454Z"
    }
   },
   "outputs": [],
   "source": [
    "!variety --port=27019 NARCIS/Dec2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We have copied the output into the file `{{FIELDS_VAR_FILE_NAME}}`, so it does not get inadvertently lost.\n",
    "After saving the output, we discarded it from the cell.\n",
    "\n",
    "The results are pleasing to the eye (if your screen is wide enough) but\n",
    "they lend themselves less well for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T09:32:32.221320Z",
     "start_time": "2018-02-07T09:32:32.093873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n",
      "| key                                                                                       | types                           | occurrences | percents                 |\r\n",
      "| ----------------------------------------------------------------------------------------- | ------------------------------- | ----------- | ------------------------ |\r\n",
      "| DAI                                                                                       | Array                           |     1622397 | 100.00000000000000000000 |\r\n",
      "| GlobalIDs                                                                                 | Array                           |     1622397 | 100.00000000000000000000 |\r\n",
      "| ID                                                                                        | Array                           |     1622397 | 100.00000000000000000000 |\r\n",
      "| Journal                                                                                   | Array                           |     1622397 | 100.00000000000000000000 |\r\n",
      "| Keywords                                                                                  | Array                           |     1622397 | 100.00000000000000000000 |\r\n",
      "| NumberofIDs                                                                               | Array                           |     1622397 | 100.00000000000000000000 |\r\n",
      "| _id                                                                                       | ObjectId                        |     1622397 | 100.00000000000000000000 |\r\n",
      "| access                                                                                    | Array                           |     1622397 | 100.00000000000000000000 |\r\n",
      "| date_harv                                                                                 | Array                           |     1622397 | 100.00000000000000000000 |\r\n",
      "| date_header                                                                               | Array                           |     1622397 | 100.00000000000000000000 |\r\n",
      "| date_orig                                                                                 | Array                           |     1622397 | 100.00000000000000000000 |\r\n",
      "| filenr                                                                                    | Array                           |     1622397 | 100.00000000000000000000 |\r\n",
      "| nldidlnorm                                                                                | Array                           |     1622397 | 100.00000000000000000000 |\r\n",
      "| nldidlnorm.XX.Component                                                                   | Object                          |     1622397 | 100.00000000000000000000 |\r\n",
      "| nldidlnorm.XX.Component.Resource                                                          | Array                           |     1622397 | 100.00000000000000000000 |\r\n",
      "| nldidlnorm.XX.Descriptor                                                                  | Object                          |     1622397 | 100.00000000000000000000 |\r\n",
      "| nldidlnorm.XX.Descriptor.Statement                                                        | Object                          |     1622397 | 100.00000000000000000000 |\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 {FIELDS_VAR_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T09:32:39.498375Z",
     "start_time": "2018-02-07T09:32:39.358014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| nldidlnorm.XX.Item.Component.Resource.mods.relatedItem4.titleInfo.title                   | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item.Component.Resource.mods.relatedItem5                                   | Object                          |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item.Component.Resource.mods.relatedItem5._attrs                            | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item.Component.Resource.mods.relatedItem5.titleInfo                         | Object                          |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item.Component.Resource.mods.relatedItem5.titleInfo.title                   | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item.Component.Resource.mods.subject0.topic0                                | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item.Component.Resource.mods.subject0.topic8                                | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item.Component.Resource.mods.subject0.topic9                                | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item0.Descriptor1.Statement.modified                                        | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item0.Descriptor3.Statement.description                                     | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item5.Descriptor1.Statement.modified                                        | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item7.Descriptor1.Statement.modified                                        | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item7.Descriptor3.Statement.description                                     | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item8.Descriptor1.Statement.modified                                        | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item8.Descriptor3.Statement.description                                     | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item9.Descriptor1.Statement.modified                                        | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "| nldidlnorm.XX.Item9.Descriptor3.Statement.description                                     | Array                           |           1 |   0.00006163719484195299 |\r\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\r\n",
      "\r\n",
      "MongoDB shell version v3.4.10\r\n",
      "connecting to: mongodb://127.0.0.1:27019/NARCIS\r\n",
      "MongoDB server version: 3.6.2\r\n",
      "WARNING: shell and server versions do not match\r\n",
      "Variety: A MongoDB Schema Analyzer\r\n",
      "Version 1.5.1, released 02 October 2017\r\n",
      "Using collection of \"Dec2017\"\r\n",
      "Using query of { }\r\n",
      "Using limit of 1622397\r\n",
      "Using maxDepth of 99\r\n",
      "Using sort of { \"_id\" : -1 }\r\n",
      "Using outputFormat of \"ascii\"\r\n",
      "Using persistResults of false\r\n",
      "Using resultsDatabase of \"varietyResults\"\r\n",
      "Using resultsCollection of \"Dec2017Keys\"\r\n",
      "Using resultsUser of null\r\n",
      "Using resultsPass of null\r\n",
      "Using logKeysContinuously of false\r\n",
      "Using excludeSubkeys of [ ]\r\n",
      "Using arrayEscape of \"XX\"\r\n",
      "Using plugins of [ ]\r\n"
     ]
    }
   ],
   "source": [
    "!tail -40 {FIELDS_VAR_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
